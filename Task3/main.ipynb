{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05742f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Hub model loaded successfully.\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://73206a2f9a8be678e6.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://73206a2f9a8be678e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "# --- Model and Preprocessing ---\n",
    "\n",
    "# Load the pre-trained model from TF Hub (loaded only once)\n",
    "try:\n",
    "    model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "    print(\"TensorFlow Hub model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    # Create a dummy model to allow the UI to load without crashing\n",
    "    model = None\n",
    "\n",
    "def preprocess_image(image_np):\n",
    "    \"\"\"\n",
    "    Takes a NumPy image, converts it to a TensorFlow tensor,\n",
    "    and preprocesses it for the model.\n",
    "    \"\"\"\n",
    "    # Gradio provides a uint8 numpy array, convert it to float32 and normalize\n",
    "    img = tf.convert_to_tensor(image_np, dtype=tf.float32)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # The model expects a 4D tensor (batch_size, height, width, channels)\n",
    "    # Add a batch dimension\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def stylize_image(content_image_np, style_image_np):\n",
    "    \"\"\"\n",
    "    Applies style transfer to the content image using the style image.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        # Return a black image with an error message if the model failed to load\n",
    "        error_img = np.zeros_like(content_image_np)\n",
    "        print(\"Model is not available. Returning a black image.\")\n",
    "        return error_img \n",
    "\n",
    "    # Preprocess both images\n",
    "    content_tensor = preprocess_image(content_image_np)\n",
    "    style_tensor = preprocess_image(style_image_np)\n",
    "\n",
    "    # Apply the style transfer model\n",
    "    outputs = model(content_tensor, style_tensor)\n",
    "    stylized_image = outputs[0]\n",
    "\n",
    "    # The output is a tensor with a batch dimension. Squeeze it and return as a NumPy array.\n",
    "    # The values are already in the [0, 1] range, which Gradio handles correctly.\n",
    "    return np.squeeze(stylized_image)\n",
    "\n",
    "# --- Gradio Interface ---\n",
    "\n",
    "description = \"\"\"\n",
    "Upload a **Content Image** and a **Style Image**. The model will then combine them,\n",
    "applying the artistic style of the Style Image to the content of the Content Image.\n",
    "The generated image will appear in the output box below, and you can download it from there.\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=stylize_image,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Content Image\", type=\"numpy\"),\n",
    "        gr.Image(label=\"Style Image\", type=\"numpy\")\n",
    "    ],\n",
    "    outputs=gr.Image(label=\"Stylized Image\", type=\"numpy\"),\n",
    "    title=\"Neural Style Transfer\",\n",
    "    description=description,\n",
    "    examples=[\n",
    "        [\"dice.png\", \"potato.png\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a082d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
