{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a8ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0545bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n",
      "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://9c29fcaf1acf3ec0e9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9c29fcaf1acf3ec0e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "from typing import List, Dict\n",
    "import gradio as gr\n",
    "import pymupdf as fitz\n",
    "\n",
    "pipe = pipeline(\"summarization\") #Hugging face function, which uses complex NLP techniques under the hood to summaries the text.\n",
    "\n",
    "def summarize(user_data: Dict , history: List) -> str:\n",
    "    \"\"\"\n",
    "    Used by the interface, receives user input and file uploads.\n",
    "\n",
    "    Args:\n",
    "        user_data (dict): Dictionary containing 'text' and 'files' keys.\n",
    "        history (list): Chat history (not used in this function).\n",
    "    Returns:\n",
    "        str: Summarized text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        message = user_data.get(\"text\", \"\")\n",
    "        files = user_data.get(\"files\", [])\n",
    "\n",
    "        if files == []: #No file uploaded, just plain text\n",
    "            summary = pipe(message)\n",
    "            output = summary[0]['summary_text']\n",
    "            return output\n",
    "        elif files != [] and message == \"\": #when only file is given\n",
    "            if files[0] == \".txt\": #pasted text is treated as .txt file\n",
    "                with open(files[0], 'r') as f:\n",
    "                    file_content = f.read()\n",
    "                summary = pipe(file_content)\n",
    "                output = summary[0]['summary_text']\n",
    "                return output\n",
    "            elif files[0] == \".pdf\": #use PyMuPDF to read pdf files\n",
    "                pdf_reader = fitz.open(files[0])\n",
    "                text = \"\"\n",
    "                for page in pdf_reader:\n",
    "                    text += page.get_text(\"text\")\n",
    "                pdf_reader.close()\n",
    "                summary = pipe(text)\n",
    "                output = summary[0]['summary_text']\n",
    "                return output\n",
    "            else:\n",
    "                return \"Unsupported file format. Please upload a .txt or .pdf file.\"\n",
    "        else:\n",
    "            return \"Please provide either text or file, not both.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(fn=summarize,\n",
    "                        title= \"Text Summarization Bot\",\n",
    "                        multimodal=True\n",
    "                        )\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
